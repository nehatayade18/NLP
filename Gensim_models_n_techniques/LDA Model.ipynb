{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model- Topic Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os.path\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "import smart_open\n",
    "\n",
    "def extract_documents(url='https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz'):\n",
    "    fname = url.split('/')[-1]\n",
    "\n",
    "    # Download the file to local storage first.\n",
    "    # We can't read it on the fly because of\n",
    "    # https://github.com/RaRe-Technologies/smart_open/issues/331\n",
    "    if not os.path.isfile(fname):\n",
    "        with smart_open.open(url, \"rb\") as fin:\n",
    "            with smart_open.open(fname, 'wb') as fout:\n",
    "                while True:\n",
    "                    buf = fin.read(io.DEFAULT_BUFFER_SIZE)\n",
    "                    if not buf:\n",
    "                        break\n",
    "                    fout.write(buf)\n",
    "\n",
    "    with tarfile.open(fname, mode='r:gz') as tar:\n",
    "        # Ignore directory entries, as well as files like README, etc.\n",
    "        files = [\n",
    "            m for m in tar.getmembers()\n",
    "            if m.isfile() and re.search(r'nipstxt/nips\\d+/\\d+\\.txt', m.name)\n",
    "        ]\n",
    "        for member in sorted(files, key=lambda x: x.name):\n",
    "            member_bytes = tar.extractfile(member).read()\n",
    "            yield member_bytes.decode('utf-8', errors='replace')\n",
    "\n",
    "docs = list(extract_documents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "1 \n",
      "CONNECTIVITY VERSUS ENTROPY \n",
      "Yaser S. Abu-Mostafa \n",
      "California Institute of Technology \n",
      "Pasadena, CA 91125 \n",
      "ABSTRACT \n",
      "How does the connectivity of a neural network (number of synapses per \n",
      "neuron) relate to the complexity of the problems it can handle (measured by \n",
      "the entropy)? Switching theory would suggest no relation at all, since all Boolean \n",
      "functions can be implemented using a circuit with very low connectivity (e.g., \n",
      "using two-input NAND gates). However, for a network that learns a pr\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "print(docs[0][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process and vectorize the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of preprocessing, we will:\n",
    "\n",
    "Tokenize (split the documents into tokens).\n",
    "\n",
    "Lemmatize the tokens.\n",
    "\n",
    "Compute bigrams.\n",
    "\n",
    "Compute a bag-of-words representation of the data.\n",
    "\n",
    "First we tokenize the text using a regular expression tokenizer from NLTK. We remove numeric tokens and tokens that are only a single character, as they don’t tend to be useful, and the dataset contains a lot of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the documents.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Split the documents into tokens.\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    #print(docs[idx])\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the WordNet lemmatizer from NLTK. A lemmatizer is preferred over a stemmer in this case because it produces more readable words. Output that is easy to read is very desirable in topic modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize the documents.\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find bigrams in the documents. Bigrams are sets of two adjacent words. Using bigrams we can get phrases like “machine_learning” in our output (spaces are replaced with underscores); without bigrams we would only get “machine” and “learning”.\n",
    "\n",
    "Note that in the code below, we find bigrams and then add them to the original data, because we would like to keep the words “machine” and “learning” as well as the bigram “machine_learning”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bigrams.\n",
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove rare words and common words based on their document frequency. Below we remove words that appear in less than 20 documents or in more than 50% of the documents. Consider trying to remove words only based on their frequency, or maybe combining that with this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we transform the documents to a vectorized form. We simply compute the frequency of each word, including the bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see how many tokens and documents we have to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 8644\n",
      "Number of documents: 1740\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, the elephant in the room: how many topics do I need? There is really no easy answer for this, it will depend on both your data and your application. I have used 10 topics here because I wanted to have a few topics that I could interpret and “label”, and because that turned out to give me reasonably good results. You might not need to interpret all your topics, so you could use a large number of topics, for example 100.\n",
    "\n",
    "chunksize controls how many documents are processed at a time in the training algorithm. Increasing chunksize will speed up training, at least as long as the chunk of documents easily fit into memory. I’ve set chunksize = 2000, which is more than the amount of documents, so I process all the data in one go. Chunksize can however influence the quality of the model, as discussed in Hoffman and co-authors [2], but the difference was not substantial in this case.\n",
    "\n",
    "passes controls how often we train the model on the entire corpus. Another word for passes might be “epochs”. iterations is somewhat technical, but essentially it controls how often we repeat a particular loop over each document. It is important to set the number of “passes” and “iterations” high enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(corpus=corpus, id2word=id2word, chunksize=chunksize, alpha='auto', eta='auto', iterations=iterations,\n",
    "    num_topics=num_topics, passes=passes, eval_every=eval_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -1.2256.\n",
      "[([(0.011576824, 'hidden'),\n",
      "   (0.007768733, 'layer'),\n",
      "   (0.0074472954, 'rule'),\n",
      "   (0.007194656, 'hidden_unit'),\n",
      "   (0.0069199684, 'net'),\n",
      "   (0.0048742425, 'trained'),\n",
      "   (0.0044969954, 'node'),\n",
      "   (0.0044710375, 'architecture'),\n",
      "   (0.004007861, 'generalization'),\n",
      "   (0.003944988, 'tree'),\n",
      "   (0.0038787045, 'training_set'),\n",
      "   (0.003527813, 'activation'),\n",
      "   (0.0035065522, 'table'),\n",
      "   (0.003415505, 'prediction'),\n",
      "   (0.003352954, 'sequence'),\n",
      "   (0.0032954707, 'back'),\n",
      "   (0.003191935, 'learn'),\n",
      "   (0.0030908016, 'recurrent'),\n",
      "   (0.003012424, 'propagation'),\n",
      "   (0.0029558474, 'connectionist')],\n",
      "  -1.020997231267583),\n",
      " ([(0.015136251, 'cell'),\n",
      "   (0.012332249, 'neuron'),\n",
      "   (0.0085421335, 'response'),\n",
      "   (0.007961597, 'visual'),\n",
      "   (0.007583173, 'stimulus'),\n",
      "   (0.0062418785, 'activity'),\n",
      "   (0.0057474663, 'spike'),\n",
      "   (0.0050667734, 'motion'),\n",
      "   (0.00478626, 'field'),\n",
      "   (0.0045401887, 'frequency'),\n",
      "   (0.0045381235, 'direction'),\n",
      "   (0.004407514, 'signal'),\n",
      "   (0.004374593, 'cortex'),\n",
      "   (0.0041994955, 'firing'),\n",
      "   (0.0040234555, 'synaptic'),\n",
      "   (0.0039412454, 'spatial'),\n",
      "   (0.0039336993, 'eye'),\n",
      "   (0.003851277, 'orientation'),\n",
      "   (0.003763312, 'connection'),\n",
      "   (0.0034092367, 'map')],\n",
      "  -1.0225284095072689),\n",
      " ([(0.0112859635, 'gaussian'),\n",
      "   (0.008135464, 'mixture'),\n",
      "   (0.007242611, 'matrix'),\n",
      "   (0.0068920497, 'hidden'),\n",
      "   (0.006576716, 'noise'),\n",
      "   (0.006476079, 'likelihood'),\n",
      "   (0.0063380413, 'em'),\n",
      "   (0.0054130205, 'variance'),\n",
      "   (0.005388365, 'estimate'),\n",
      "   (0.004530162, 'prediction'),\n",
      "   (0.0044812164, 'density'),\n",
      "   (0.00443345, 'approximation'),\n",
      "   (0.0044163275, 'covariance'),\n",
      "   (0.00436308, 'component'),\n",
      "   (0.0038574666, 'expert'),\n",
      "   (0.0038028522, 'estimation'),\n",
      "   (0.003784314, 'posterior'),\n",
      "   (0.0037644021, 'prior'),\n",
      "   (0.0032456722, 'code'),\n",
      "   (0.0032382268, 'field')],\n",
      "  -1.0594796274914031),\n",
      " ([(0.008688827, 'bound'),\n",
      "   (0.007816057, 'class'),\n",
      "   (0.0065527577, 'sample'),\n",
      "   (0.005728913, 'log'),\n",
      "   (0.0056279497, 'let'),\n",
      "   (0.0049450845, 'node'),\n",
      "   (0.0048738294, 'theorem'),\n",
      "   (0.0045896024, 'bayesian'),\n",
      "   (0.0044683954, 'density'),\n",
      "   (0.004154014, 'estimate'),\n",
      "   (0.004145134, 'prior'),\n",
      "   (0.0040235883, 'tree'),\n",
      "   (0.0033711027, 'dimension'),\n",
      "   (0.0033296414, 'xi'),\n",
      "   (0.0033191524, 'approximation'),\n",
      "   (0.0032944228, 'loss'),\n",
      "   (0.0032019375, 'complexity'),\n",
      "   (0.0029016803, 'likelihood'),\n",
      "   (0.0028638642, 'classification'),\n",
      "   (0.002844923, 'decision')],\n",
      "  -1.0938140068206657),\n",
      " ([(0.016252905, 'neuron'),\n",
      "   (0.012583985, 'circuit'),\n",
      "   (0.009845237, 'signal'),\n",
      "   (0.009660972, 'chip'),\n",
      "   (0.009607792, 'analog'),\n",
      "   (0.00645815, 'voltage'),\n",
      "   (0.0055562, 'net'),\n",
      "   (0.005461046, 'threshold'),\n",
      "   (0.0052668354, 'layer'),\n",
      "   (0.00510939, 'bit'),\n",
      "   (0.0050030667, 'memory'),\n",
      "   (0.0046220752, 'delay'),\n",
      "   (0.0045076855, 'connection'),\n",
      "   (0.0044643306, 'vlsi'),\n",
      "   (0.0044012675, 'implementation'),\n",
      "   (0.0040286374, 'noise'),\n",
      "   (0.0036903643, 'gate'),\n",
      "   (0.0034910506, 'processor'),\n",
      "   (0.0034575132, 'channel'),\n",
      "   (0.0034162123, 'node')],\n",
      "  -1.2209837682430058),\n",
      " ([(0.009777363, 'gradient'),\n",
      "   (0.0066944147, 'noise'),\n",
      "   (0.005770583, 'optimal'),\n",
      "   (0.005039133, 'generalization'),\n",
      "   (0.0046325484, 'convergence'),\n",
      "   (0.004389832, 'rule'),\n",
      "   (0.0043473104, 'source'),\n",
      "   (0.004193304, 'descent'),\n",
      "   (0.0039407965, 'matrix'),\n",
      "   (0.0038959272, 'solution'),\n",
      "   (0.0038725042, 'signal'),\n",
      "   (0.0038187704, 'learning_rate'),\n",
      "   (0.003778562, 'minimum'),\n",
      "   (0.0036575256, 'stochastic'),\n",
      "   (0.0033766285, 'cost'),\n",
      "   (0.0033029292, 'teacher'),\n",
      "   (0.0031797637, 'student'),\n",
      "   (0.0030919535, 'component'),\n",
      "   (0.0029538008, 'independent'),\n",
      "   (0.0028140906, 'eq')],\n",
      "  -1.2937201309312694),\n",
      " ([(0.020226117, 'image'),\n",
      "   (0.014272173, 'object'),\n",
      "   (0.008204406, 'field'),\n",
      "   (0.0053568953, 'cluster'),\n",
      "   (0.0052110306, 'constraint'),\n",
      "   (0.0046796384, 'map'),\n",
      "   (0.0045754807, 'energy'),\n",
      "   (0.004536065, 'distance'),\n",
      "   (0.004349731, 'position'),\n",
      "   (0.0040515964, 'graph'),\n",
      "   (0.003971475, 'pixel'),\n",
      "   (0.0039135274, 'recognition'),\n",
      "   (0.0037121896, 'view'),\n",
      "   (0.0033146313, 'surface'),\n",
      "   (0.0033000405, 'transformation'),\n",
      "   (0.0032591799, 'clustering'),\n",
      "   (0.0031232454, 'vision'),\n",
      "   (0.0031205327, 'character'),\n",
      "   (0.002939355, 'matching'),\n",
      "   (0.0029238358, 'mapping')],\n",
      "  -1.375029069291881),\n",
      " ([(0.0073971273, 'kernel'),\n",
      "   (0.0067104227, 'matrix'),\n",
      "   (0.005392209, 'regression'),\n",
      "   (0.005036785, 'distance'),\n",
      "   (0.00500193, 'approximation'),\n",
      "   (0.0045943907, 'solution'),\n",
      "   (0.0045823175, 'class'),\n",
      "   (0.0045450567, 'xi'),\n",
      "   (0.0043433225, 'nonlinear'),\n",
      "   (0.0040492336, 'support'),\n",
      "   (0.004009042, 'dimensional'),\n",
      "   (0.0038702954, 'basis'),\n",
      "   (0.0036157519, 'let'),\n",
      "   (0.003510941, 'condition'),\n",
      "   (0.0033814462, 'projection'),\n",
      "   (0.0032927827, 'tangent'),\n",
      "   (0.0029922016, 'optimization'),\n",
      "   (0.0029304984, 'component'),\n",
      "   (0.00284371, 'operator'),\n",
      "   (0.002718089, 'margin')],\n",
      "  -1.3813338901680732),\n",
      " ([(0.013015045, 'action'),\n",
      "   (0.012480096, 'control'),\n",
      "   (0.009032468, 'policy'),\n",
      "   (0.00822534, 'memory'),\n",
      "   (0.008102448, 'dynamic'),\n",
      "   (0.007694577, 'reinforcement'),\n",
      "   (0.0058084475, 'optimal'),\n",
      "   (0.005627221, 'robot'),\n",
      "   (0.005150068, 'reinforcement_learning'),\n",
      "   (0.005042703, 'controller'),\n",
      "   (0.004855809, 'environment'),\n",
      "   (0.004195476, 'reward'),\n",
      "   (0.004163733, 'trajectory'),\n",
      "   (0.0038996295, 'goal'),\n",
      "   (0.003609537, 'transition'),\n",
      "   (0.003294435, 'path'),\n",
      "   (0.0031529958, 'capacity'),\n",
      "   (0.003078285, 'agent'),\n",
      "   (0.0029492336, 'sutton'),\n",
      "   (0.0028990044, 'neuron')],\n",
      "  -1.392291133403974),\n",
      " ([(0.015842227, 'recognition'),\n",
      "   (0.011755905, 'speech'),\n",
      "   (0.010932465, 'word'),\n",
      "   (0.010863044, 'image'),\n",
      "   (0.009423061, 'classifier'),\n",
      "   (0.0075103957, 'class'),\n",
      "   (0.0068646492, 'classification'),\n",
      "   (0.005585241, 'face'),\n",
      "   (0.0044044885, 'context'),\n",
      "   (0.004375981, 'speaker'),\n",
      "   (0.004204233, 'hmm'),\n",
      "   (0.004132424, 'trained'),\n",
      "   (0.0041292524, 'layer'),\n",
      "   (0.00402305, 'sequence'),\n",
      "   (0.0038276284, 'frame'),\n",
      "   (0.0037364038, 'hidden'),\n",
      "   (0.0030454865, 'acoustic'),\n",
      "   (0.003005952, 'rbf'),\n",
      "   (0.0029364706, 'database'),\n",
      "   (0.0028711145, 'phoneme')],\n",
      "  -1.396211042154362)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
